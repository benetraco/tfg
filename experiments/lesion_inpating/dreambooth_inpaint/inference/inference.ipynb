{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  MS Lesion Synthesis Inference Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler, StableDiffusionInpaintPipeline, UNet2DConditionModel\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "seed = 17844"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simple_lesion(image, mask, lesion_size, lesion_intensity):\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = transforms.ToTensor()(image).unsqueeze(0)\n",
    "    lesion = torch.zeros_like(image)\n",
    "    lesion[0, 0, mask[0]:mask[0]+lesion_size[0], mask[1]:mask[1]+lesion_size[1]] = lesion_intensity\n",
    "    return lesion\n",
    "\n",
    "def generate_mask(image, mask_size, mask_position, show=True):\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = transforms.ToTensor()(image).unsqueeze(0)\n",
    "    \n",
    "    mask = torch.zeros_like(image)\n",
    "    mask[0, 0, mask_position[0]:mask_position[0]+mask_size[0], mask_position[1]:mask_position[1]+mask_size[1]] = 1\n",
    "    \n",
    "    if show:\n",
    "        plt.imshow(mask[0, 0].cpu().numpy(), cmap='gray')\n",
    "        plt.show()\n",
    "        print(f\"Mask generated. Size: {mask_size}, position: {mask_position}\")\n",
    "    return mask\n",
    "\n",
    "def generate_lesion(pipe, image, mask, prompt, guidance, device='cuda', seed=17844):\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "    return pipe(prompt=prompt,\n",
    "                image=image,\n",
    "                mask_image=mask,\n",
    "                num_inference_steps=25,\n",
    "                generator=generator,\n",
    "                guidance=guidance, #guidance_scale??\n",
    "            ).images[0]\n",
    "\n",
    "def load_image(path, size=256, show=True):\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.CenterCrop(size)\n",
    "    ])(image)\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        print(f\"Image {path} loaded. Size: {image.size}, mode: {image.mode}\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---- Load pipeline ----\n",
    "# model_path = \"../lesion-inpating-dreambooth-model-new\"        # <- Replace this with your fine-tuned model folder\n",
    "# device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "#     model_path,\n",
    "#     torch_dtype=torch.float32,\n",
    "#     safety_checker=None,\n",
    "# )\n",
    "\n",
    "# pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe = pipe.to(device)\n",
    "# # pipe.set_progress_bar_config(disable=True)\n",
    "# # inspect.signature(pipe.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./input_data/flair.png\"                     # <- Path to FLAIR MRI image (PNG, JPG)\n",
    "prompt = \"Multiple sclerosis lesion inpainting\"           # <- Prompt for the model\n",
    "output_path = \"./output_data/lesion_output.png\"           # <- Where to save the output\n",
    "image_size = 512  # Assumes model was trained at 512x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incorrect configuration settings! The config of `pipeline.unet`: FrozenDict({'sample_size': 64, 'in_channels': 9, 'out_channels': 4, 'center_input_sample': False, 'flip_sin_to_cos': True, 'freq_shift': 0, 'down_block_types': ['CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'DownBlock2D'], 'mid_block_type': 'UNetMidBlock2DCrossAttn', 'up_block_types': ['UpBlock2D', 'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D'], 'only_cross_attention': False, 'block_out_channels': [320, 640, 1280, 1280], 'layers_per_block': 2, 'downsample_padding': 1, 'mid_block_scale_factor': 1, 'dropout': 0.0, 'act_fn': 'silu', 'norm_num_groups': 32, 'norm_eps': 1e-05, 'cross_attention_dim': 768, 'transformer_layers_per_block': 1, 'reverse_transformer_layers_per_block': None, 'encoder_hid_dim': None, 'encoder_hid_dim_type': None, 'attention_head_dim': 8, 'num_attention_heads': None, 'dual_cross_attention': False, 'use_linear_projection': False, 'class_embed_type': None, 'addition_embed_type': None, 'addition_time_embed_dim': None, 'num_class_embeds': None, 'upcast_attention': False, 'resnet_time_scale_shift': 'default', 'resnet_skip_time_act': False, 'resnet_out_scale_factor': 1.0, 'time_embedding_type': 'positional', 'time_embedding_dim': None, 'time_embedding_act_fn': None, 'timestep_post_act': None, 'time_cond_proj_dim': None, 'conv_in_kernel': 3, 'conv_out_kernel': 3, 'projection_class_embeddings_input_dim': None, 'attention_type': 'default', 'class_embeddings_concat': False, 'mid_block_only_cross_attention': None, 'cross_attention_norm': None, 'addition_embed_type_num_heads': 64, '_class_name': 'UNet2DConditionModel', '_diffusers_version': '0.32.2', '_name_or_path': '../lesion-inpating-dreambooth-model-new/unet'}) expects 9 but received `num_channels_latents`: 4 + `num_channels_mask`: 3 + `num_channels_masked_image`: 4 = 11. Please verify the config of `pipeline.unet` or your `mask_image` or `image` input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m lesion \u001b[38;5;241m=\u001b[39m generate_simple_lesion(image, mask_position, lesion_size, lesion_intensity)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Generate lesion\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m lesion \u001b[38;5;241m=\u001b[39m generate_lesion(pipe, image, mask, prompt, lesion)\n",
      "Cell \u001b[0;32mIn[184], line 23\u001b[0m, in \u001b[0;36mgenerate_lesion\u001b[0;34m(pipe, image, mask, prompt, guidance, device, seed)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_lesion\u001b[39m(pipe, image, mask, prompt, guidance, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m17844\u001b[39m):\n\u001b[1;32m     22\u001b[0m     generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator(device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pipe(prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     24\u001b[0m                 image\u001b[38;5;241m=\u001b[39mimage,\n\u001b[1;32m     25\u001b[0m                 mask_image\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m     26\u001b[0m                 num_inference_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m     27\u001b[0m                 generator\u001b[38;5;241m=\u001b[39mgenerator,\n\u001b[1;32m     28\u001b[0m                 guidance\u001b[38;5;241m=\u001b[39mguidance, \u001b[38;5;66;03m#guidance_scale??\u001b[39;00m\n\u001b[1;32m     29\u001b[0m             )\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/benetvicorob/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/benetvicorob/lib/python3.12/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_inpaint.py:1207\u001b[0m, in \u001b[0;36mStableDiffusionInpaintPipeline.__call__\u001b[0;34m(self, prompt, image, mask_image, masked_image_latents, height, width, padding_mask_crop, strength, num_inference_steps, timesteps, sigmas, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     num_channels_masked_image \u001b[38;5;241m=\u001b[39m masked_image_latents\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_channels_latents \u001b[38;5;241m+\u001b[39m num_channels_mask \u001b[38;5;241m+\u001b[39m num_channels_masked_image \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39min_channels:\n\u001b[0;32m-> 1207\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1208\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect configuration settings! The config of `pipeline.unet`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1209\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39min_channels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but received `num_channels_latents`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_channels_latents\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m +\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1210\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `num_channels_mask`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_channels_mask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m + `num_channels_masked_image`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_channels_masked_image\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_channels_latents\u001b[38;5;241m+\u001b[39mnum_channels_masked_image\u001b[38;5;241m+\u001b[39mnum_channels_mask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please verify the config of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1212\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `pipeline.unet` or your `mask_image` or `image` input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m         )\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m num_channels_unet \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1216\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe unet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should have either 4 or 9 input channels, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39min_channels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1217\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Incorrect configuration settings! The config of `pipeline.unet`: FrozenDict({'sample_size': 64, 'in_channels': 9, 'out_channels': 4, 'center_input_sample': False, 'flip_sin_to_cos': True, 'freq_shift': 0, 'down_block_types': ['CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'DownBlock2D'], 'mid_block_type': 'UNetMidBlock2DCrossAttn', 'up_block_types': ['UpBlock2D', 'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D'], 'only_cross_attention': False, 'block_out_channels': [320, 640, 1280, 1280], 'layers_per_block': 2, 'downsample_padding': 1, 'mid_block_scale_factor': 1, 'dropout': 0.0, 'act_fn': 'silu', 'norm_num_groups': 32, 'norm_eps': 1e-05, 'cross_attention_dim': 768, 'transformer_layers_per_block': 1, 'reverse_transformer_layers_per_block': None, 'encoder_hid_dim': None, 'encoder_hid_dim_type': None, 'attention_head_dim': 8, 'num_attention_heads': None, 'dual_cross_attention': False, 'use_linear_projection': False, 'class_embed_type': None, 'addition_embed_type': None, 'addition_time_embed_dim': None, 'num_class_embeds': None, 'upcast_attention': False, 'resnet_time_scale_shift': 'default', 'resnet_skip_time_act': False, 'resnet_out_scale_factor': 1.0, 'time_embedding_type': 'positional', 'time_embedding_dim': None, 'time_embedding_act_fn': None, 'timestep_post_act': None, 'time_cond_proj_dim': None, 'conv_in_kernel': 3, 'conv_out_kernel': 3, 'projection_class_embeddings_input_dim': None, 'attention_type': 'default', 'class_embeddings_concat': False, 'mid_block_only_cross_attention': None, 'cross_attention_norm': None, 'addition_embed_type_num_heads': 64, '_class_name': 'UNet2DConditionModel', '_diffusers_version': '0.32.2', '_name_or_path': '../lesion-inpating-dreambooth-model-new/unet'}) expects 9 but received `num_channels_latents`: 4 + `num_channels_mask`: 3 + `num_channels_masked_image`: 4 = 11. Please verify the config of `pipeline.unet` or your `mask_image` or `image` input."
     ]
    }
   ],
   "source": [
    "# Load image and mask\n",
    "image = load_image(image_path, image_size, show=False)\n",
    "\n",
    "# Generate mask\n",
    "mask_size = (27, 33)\n",
    "mask_position = (150, 150)\n",
    "mask = generate_mask(image, mask_size, mask_position, show=False)\n",
    "\n",
    "# Generate simple lesion\n",
    "lesion_size = (15, 15)\n",
    "lesion_intensity = 0.5\n",
    "lesion = generate_simple_lesion(image, mask_position, lesion_size, lesion_intensity)\n",
    "\n",
    "# Generate lesion\n",
    "lesion = generate_lesion(pipe, image, mask, prompt, lesion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benetvicorob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
