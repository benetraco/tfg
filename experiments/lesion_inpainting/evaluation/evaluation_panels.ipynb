{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b655c99",
   "metadata": {},
   "source": [
    "# Notebook to create the panel images to upload in the google forms for evaluation of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e5be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d02722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluation_panels_final_randomized(flair_folder, mask_folder, generated_folders, output_folder, metadata_csv, size=512):\n",
    "    \"\"\"\n",
    "    This function generates visual evaluation panels for synthetic lesion assessment.\n",
    "    It combines original FLAIR images, synthetic masks, overlays, and generated outputs\n",
    "    from multiple models into a unified image. The generated images are randomized\n",
    "    in position (A, B, C), and a mapping is saved for later analysis.\n",
    "\n",
    "    Inputs:\n",
    "    - flair_folder: path to original FLAIR images\n",
    "    - mask_folder: path to synthetic lesion masks\n",
    "    - generated_folders: dict of model name -> path to generated lesion images\n",
    "    - output_folder: where final panel images are saved\n",
    "    - metadata_csv: path to CSV that stores A/B/C -> model mappings\n",
    "\n",
    "    Output:\n",
    "    - For each image: a 2-row panel image (top: original/mask/overlay, bottom: A/B/C outputs)\n",
    "    - CSV: with filename and which model corresponds to each label (A, B, C)\n",
    "    \"\"\"\n",
    "\n",
    "    flair_folder = Path(flair_folder)\n",
    "    mask_folder = Path(mask_folder)\n",
    "    output_folder = Path(output_folder)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Resize(size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(size)\n",
    "    ])\n",
    "\n",
    "    def torch_transform(pil_img):\n",
    "        return image_transform(pil_img)\n",
    "\n",
    "    def add_title(image, title, size, font_path=\"./fonts/DejaVuSans.ttf\"):\n",
    "        new_img = Image.new(\"RGB\", (size, size + 40), (255, 255, 255))\n",
    "        new_img.paste(image, (0, 0))\n",
    "        draw = ImageDraw.Draw(new_img)\n",
    "\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, 28)\n",
    "        except:\n",
    "            print(\"Font not found, using default small font\")\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        bbox = draw.textbbox((0, 0), title, font=font)\n",
    "        text_w = bbox[2] - bbox[0]\n",
    "        draw.text(((size - text_w) // 2, size + 5), title, fill=(0, 0, 0), font=font)\n",
    "        return new_img\n",
    "\n",
    "    flair_images = list(Path(flair_folder).glob(\"*.png\"))\n",
    "    model_names = sorted(generated_folders.keys())\n",
    "    metadata = []\n",
    "\n",
    "    for flair_path in flair_images:\n",
    "        base_name = flair_path.name\n",
    "        mask_path = Path(mask_folder) / base_name\n",
    "\n",
    "        if not mask_path.exists():\n",
    "            print(f\"Skipping {base_name}: mask missing\")\n",
    "            continue\n",
    "\n",
    "        flair_img = Image.open(flair_path).convert(\"RGB\")\n",
    "        mask_img = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        flair_np = np.array(flair_img)\n",
    "        mask_np = np.array(mask_img)\n",
    "        contours = measure.find_contours(mask_np > 0, 0.5)\n",
    "        for contour in contours:\n",
    "            for y, x in contour.astype(np.int32):\n",
    "                if 0 <= y < flair_np.shape[0] and 0 <= x < flair_np.shape[1]:\n",
    "                    flair_np[y, x] = [255, 0, 0]\n",
    "        overlay_img = Image.fromarray(flair_np)\n",
    "\n",
    "        flair_img = torch_transform(flair_img)\n",
    "        mask_rgb = torch_transform(Image.fromarray(np.stack([mask_np]*3, axis=-1)))\n",
    "        overlay_img = torch_transform(overlay_img)\n",
    "\n",
    "        top_row = [\n",
    "            add_title(flair_img, \"Original\", size),\n",
    "            add_title(mask_rgb, \"Mask\", size),\n",
    "            add_title(overlay_img, \"Overlay\", size),\n",
    "        ]\n",
    "\n",
    "        model_to_image = {}\n",
    "        for model in model_names:\n",
    "            gen_path = Path(generated_folders[model]) / base_name\n",
    "            if gen_path.exists():\n",
    "                gen_img = torch_transform(Image.open(gen_path).convert(\"RGB\"))\n",
    "                model_to_image[model] = gen_img\n",
    "            else:\n",
    "                print(f\"Skipping {base_name}: missing image for model {model}\")\n",
    "                break\n",
    "\n",
    "        if len(model_to_image) != 3:\n",
    "            continue\n",
    "\n",
    "        # Randomize model-to-label mapping\n",
    "        items = list(model_to_image.items())\n",
    "        random.shuffle(items)\n",
    "        label_to_model = dict(zip(['A', 'B', 'C'], [model for model, _ in items]))\n",
    "        images_ordered = [img for _, img in items]\n",
    "\n",
    "        bottom_row = [add_title(img, label, size) for img, label in zip(images_ordered, ['A', 'B', 'C'])]\n",
    "\n",
    "        composite = Image.new('RGB', (size * 3, (size + 40) * 2), (255, 255, 255))\n",
    "        for i, img in enumerate(top_row):\n",
    "            composite.paste(img, (i * size, 0))\n",
    "        for i, img in enumerate(bottom_row):\n",
    "            composite.paste(img, (i * size, size + 40))\n",
    "\n",
    "        composite.save(Path(output_folder) / base_name)\n",
    "        metadata.append({\n",
    "            \"filename\": base_name,\n",
    "            \"A\": label_to_model['A'],\n",
    "            \"B\": label_to_model['B'],\n",
    "            \"C\": label_to_model['C'],\n",
    "        })\n",
    "        print(f\"Saved {base_name}\")\n",
    "\n",
    "    with open(metadata_csv, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['filename', 'A', 'B', 'C']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(metadata)\n",
    "    print(f\"Metadata saved to {metadata_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebb8049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved WMH2017_27_9.png\n",
      "Saved eval_in_30_12.png\n",
      "Saved dev_out_22_7.png\n",
      "Saved dev_out_24_4.png\n",
      "Saved VH_749_6.png\n",
      "Saved VH_741_1.png\n",
      "Saved train_14_5.png\n",
      "Saved eval_in_18_3.png\n",
      "Saved VH_746_5.png\n",
      "Saved VH_752_10.png\n",
      "Saved VH_727_8.png\n",
      "Saved VH_754_11.png\n",
      "Saved WMH2017_132_2.png\n",
      "Saved WMH2017_58_7.png\n",
      "Saved WMH2017_103_6.png\n",
      "Saved dev_out_25_8.png\n",
      "Saved eval_in_4_9.png\n",
      "Saved train_22_0.png\n",
      "Saved VH_758_12.png\n",
      "Saved train_4_11.png\n",
      "Saved WMH2017_56_0.png\n",
      "Saved train_32_6.png\n",
      "Saved WMH2017_50_1.png\n",
      "Saved train_6_2.png\n",
      "Saved dev_in_4_1.png\n",
      "Saved WMH2017_59_5.png\n",
      "Saved WMH2017_6_11.png\n",
      "Saved WMH2017_101_4.png\n",
      "Saved WMH2017_137_8.png\n",
      "Saved WMH2017_65_3.png\n",
      "Saved WMH2017_33_10.png\n",
      "Saved VH_751_9.png\n",
      "Saved WMH2017_126_12.png\n",
      "Saved VH_729_2.png\n",
      "Saved VH_745_4.png\n",
      "Saved VH_738_7.png\n",
      "Saved eval_in_25_10.png\n",
      "Saved VH_648_0.png\n",
      "Saved VH_739_3.png\n",
      "Metadata saved to ./evaluation_panels_big/model_order.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "flair_folder = \"./test_images/flair\"\n",
    "mask_folder = \"./test_images/synthetic_masks_big\"\n",
    "generated_folders = {\n",
    "    \"vh\": \"./test_images/generated_lesions_big/vh\",\n",
    "    \"vh_shifts\": \"./test_images/generated_lesions_big/vh_shifts\",\n",
    "    \"vh_shifts_wmh\": \"./test_images/generated_lesions_big/vh_shifts_wmh\",\n",
    "}\n",
    "output_folder = \"./evaluation_panels_big\"\n",
    "metadata_csv = \"./evaluation_panels_big/model_order.csv\"\n",
    "\n",
    "create_evaluation_panels_final_randomized(flair_folder, mask_folder, generated_folders, output_folder, metadata_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benetvicorob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
