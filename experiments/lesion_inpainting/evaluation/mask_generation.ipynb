{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1e1122",
   "metadata": {},
   "source": [
    "# Notebook to generate realistic masks on already lesioned images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17f926c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pulp\n",
    "import shutil\n",
    "import ants\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad362a",
   "metadata": {},
   "source": [
    "### Count the subject IDs in the test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28a1908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_and_list_middle_numbers(directory, dataset_name):\n",
    "    \"\"\"\n",
    "    Count and list the distinct subject IDs (middle numbers) for a given dataset.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Directory containing the .png files.\n",
    "        dataset_name (str): One of ['VH', 'WMH2017', 'SHIFTS'].\n",
    "\n",
    "    Returns:\n",
    "        int: Number of distinct subject IDs.\n",
    "    \"\"\"\n",
    "    middle_numbers = set()\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.endswith(\".png\"):\n",
    "            continue\n",
    "\n",
    "        if dataset_name in ['VH', 'WMH2017'] and filename.startswith(dataset_name + \"_\"):\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                middle_numbers.add(int(parts[1]))\n",
    "\n",
    "        elif dataset_name == 'SHIFTS':\n",
    "            if filename.startswith('train_'):\n",
    "                parts = filename.split('_')\n",
    "                if len(parts) >= 3:\n",
    "                    middle_numbers.add(parts[0]+parts[1])\n",
    "            elif filename.startswith(('dev_in', 'eval_in', 'dev_out')):\n",
    "                parts = filename.split('_')\n",
    "                if len(parts) >= 4:\n",
    "                    middle_numbers.add(parts[0]+parts[1]+parts[2])\n",
    "\n",
    "    sorted_ids = sorted(middle_numbers)\n",
    "    print(f\"{dataset_name}: {len(sorted_ids)} distinct subject IDs\")\n",
    "    print(\"Subject IDs:\", ', '.join(map(str, sorted_ids)))\n",
    "    \n",
    "    # return len(sorted_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66067065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VH: 18 distinct subject IDs\n",
      "Subject IDs: 648, 727, 728, 729, 738, 739, 741, 743, 744, 745, 746, 747, 749, 751, 752, 754, 755, 758\n",
      "WMH2017: 18 distinct subject IDs\n",
      "Subject IDs: 6, 27, 29, 31, 33, 37, 39, 49, 50, 56, 58, 59, 65, 101, 103, 126, 132, 137\n",
      "SHIFTS: 30 distinct subject IDs\n",
      "Subject IDs: devin2, devin4, devin6, devout14, devout18, devout20, devout21, devout22, devout24, devout25, devout8, evalin10, evalin18, evalin19, evalin21, evalin25, evalin30, evalin33, evalin4, evalin5, evalin9, train14, train19, train22, train23, train28, train3, train32, train4, train6\n",
      "VH: 18 distinct subject IDs\n",
      "Subject IDs: 648, 727, 728, 729, 738, 739, 741, 743, 744, 745, 746, 747, 749, 751, 752, 754, 755, 758\n",
      "WMH2017: 18 distinct subject IDs\n",
      "Subject IDs: 6, 27, 29, 31, 33, 37, 39, 49, 50, 56, 58, 59, 65, 101, 103, 126, 132, 137\n",
      "SHIFTS: 30 distinct subject IDs\n",
      "Subject IDs: devin2, devin4, devin6, devout14, devout18, devout20, devout21, devout22, devout24, devout25, devout8, evalin10, evalin18, evalin19, evalin21, evalin25, evalin30, evalin33, evalin4, evalin5, evalin9, train14, train19, train22, train23, train28, train3, train32, train4, train6\n"
     ]
    }
   ],
   "source": [
    "directory = \"/home/benet/data/lesion2D_VH-SHIFTS-WMH2017_empty_masks/test/flair\"\n",
    "\n",
    "count_and_list_middle_numbers(directory, 'VH')\n",
    "count_and_list_middle_numbers(directory, 'WMH2017')\n",
    "count_and_list_middle_numbers(directory, 'SHIFTS')\n",
    "\n",
    "directory = \"/home/benet/data/lesion2D_VH-SHIFTS-WMH2017_empty_masks/test/mask\"\n",
    "count_and_list_middle_numbers(directory, 'VH')\n",
    "count_and_list_middle_numbers(directory, 'WMH2017')\n",
    "count_and_list_middle_numbers(directory, 'SHIFTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54000b",
   "metadata": {},
   "source": [
    "### Select and save the test images that will be used with their masks (created)\n",
    "\n",
    "1. Create a table of area of masks for each subject and slice\n",
    "2. Select one image per dataset and slice of different subjects so that the total area is minimal (this way we select the helthier images)\n",
    "3. Save the selected images and their masks in a new folder\n",
    "4. Segment the selected images into WM/GM/CSF\n",
    "5. Create the masks for this new images based on masks from other images in the same slice and that they are not in the CSF/GM areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bded49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_area_table(directory, dataset_name):\n",
    "    \"\"\"\n",
    "    Builds a table with rows as subject IDs, columns as slice numbers, and values as white pixel area.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the folder containing mask .png files.\n",
    "        dataset_name (str): One of ['VH', 'WMH2017', 'SHIFTS'].\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Table of area values per subject and slice.\n",
    "    \"\"\"\n",
    "    table = {}\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.endswith(\".png\"):\n",
    "            continue\n",
    "\n",
    "        if dataset_name in ['VH', 'WMH2017'] and filename.startswith(dataset_name + \"_\"):\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                subject_id = int(parts[1])\n",
    "                slice_id = int(parts[2].replace(\".png\", \"\"))\n",
    "        elif dataset_name == 'SHIFTS':\n",
    "            parts = filename.split('_')\n",
    "            if filename.startswith('train_') and len(parts) >= 3:\n",
    "                subject_id = parts[0] + '_' + parts[1]\n",
    "                slice_id = int(parts[2].replace(\".png\", \"\"))\n",
    "            elif filename.startswith(('dev_in', 'eval_in', 'dev_out')) and len(parts) >= 4:\n",
    "                subject_id = parts[0] + '_' + parts[1] + '_' + parts[2]\n",
    "                slice_id = int(parts[3].replace(\".png\", \"\"))\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Load mask image in grayscale\n",
    "        image_path = os.path.join(directory, filename)\n",
    "        mask = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if mask is None:\n",
    "            print(f\"Warning: could not read image {filename}\")\n",
    "            continue\n",
    "\n",
    "        # Compute white pixel area (assuming white is 255)\n",
    "        # white_area = np.sum(mask == 255)\n",
    "        white_area = np.sum(mask > 0)\n",
    "\n",
    "        # Store in table\n",
    "        if subject_id not in table:\n",
    "            table[subject_id] = {}\n",
    "        table[subject_id][slice_id] = white_area\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame.from_dict(table, orient='index').sort_index(axis=0).sort_index(axis=1)\n",
    "    df.index.name = 'Subject ID'\n",
    "    df.columns.name = 'Slice Number'\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def find_min_area_combination(df):\n",
    "    \"\"\"\n",
    "    Select one value per column (slice) from different rows (subjects) to minimize total area.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Rows are subjects, columns are slices, values are areas.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (min_area, selected_subjects_dict) where keys are slice IDs and values are subject IDs.\n",
    "    \"\"\"\n",
    "    slice_ids = df.columns.tolist()\n",
    "    subject_ids = df.index.tolist()\n",
    "\n",
    "    # Filter subjects that have all 13 slices\n",
    "    valid_subjects = [s for s in subject_ids if df.loc[s].count() == len(slice_ids)]\n",
    "\n",
    "    if len(valid_subjects) < len(slice_ids):\n",
    "        raise ValueError(\"Not enough subjects with all slices to perform selection.\")\n",
    "\n",
    "    # Create a list of candidate subjects for each slice\n",
    "    candidates = {slice_id: df[slice_id].dropna().sort_values().index.tolist()\n",
    "                  for slice_id in slice_ids}\n",
    "\n",
    "    # Brute-force all combinations of subjects (one per slice)\n",
    "    best_total = float('inf')\n",
    "    best_combo = None\n",
    "\n",
    "    for combo in itertools.permutations(df.index, r=len(slice_ids)):\n",
    "        if len(set(combo)) != len(slice_ids):\n",
    "            continue  # Skip if subject appears more than once\n",
    "\n",
    "        total = 0\n",
    "        valid = True\n",
    "        for i, subject in enumerate(combo):\n",
    "            area = df.iloc[df.index.get_loc(subject), i]\n",
    "            if pd.isna(area):\n",
    "                valid = False\n",
    "                break\n",
    "            total += area\n",
    "\n",
    "        if valid and total < best_total:\n",
    "            best_total = total\n",
    "            best_combo = {slice_ids[i]: combo[i] for i in range(len(slice_ids))}\n",
    "\n",
    "    return best_total, best_combo\n",
    "\n",
    "\n",
    "def solve_min_area_ilp(df):\n",
    "    \"\"\"\n",
    "    Solve the minimal-area mask combination problem using ILP.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Rows = subject IDs, Columns = slice IDs, Values = areas.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (total_area, {slice_id: subject_id})\n",
    "    \"\"\"\n",
    "    df = df.dropna()  # Ensure no NaNs\n",
    "    subjects = df.index.tolist()\n",
    "    slices = df.columns.tolist()\n",
    "\n",
    "    # Define problem\n",
    "    prob = pulp.LpProblem(\"Minimize_Total_Mask_Area\", pulp.LpMinimize)\n",
    "\n",
    "    # Define binary decision variables: x[s, sl] = 1 if subject s is chosen for slice sl\n",
    "    x = pulp.LpVariable.dicts(\"x\", ((s, sl) for s in subjects for sl in slices), cat='Binary')\n",
    "\n",
    "    # Objective: minimize total area\n",
    "    prob += pulp.lpSum(x[s, sl] * df.at[s, sl] for s in subjects for sl in slices)\n",
    "\n",
    "    # Constraint: exactly one subject selected per slice\n",
    "    for sl in slices:\n",
    "        prob += pulp.lpSum(x[s, sl] for s in subjects) == 1\n",
    "\n",
    "    # Constraint: each subject can only be used once (across all slices)\n",
    "    for s in subjects:\n",
    "        prob += pulp.lpSum(x[s, sl] for sl in slices) <= 1\n",
    "\n",
    "    # Solve\n",
    "    solver = pulp.PULP_CBC_CMD(msg=False)\n",
    "    prob.solve(solver)\n",
    "\n",
    "    # Extract solution\n",
    "    selected = {sl: s for s in subjects for sl in slices if pulp.value(x[s, sl]) == 1}\n",
    "    total_area = sum(df.at[s, sl] for sl, s in selected.items())\n",
    "\n",
    "    return total_area, selected\n",
    "\n",
    "def copy_selected_masks(df, selected, dataset_name, src_dir, dst_dir):\n",
    "    \"\"\"\n",
    "    Copy selected mask files based on the subject-slice mapping into a new folder.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Area DataFrame (subject Ã— slice).\n",
    "        selected (dict): Mapping {slice_id: subject_id}.\n",
    "        dataset_name (str): One of ['VH', 'WMH2017', 'SHIFTS'].\n",
    "        src_dir (str): Path to the folder containing original mask .png files.\n",
    "        dst_dir (str): Destination directory for selected masks.\n",
    "    \"\"\"\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    for slice_id, subject_id in selected.items():\n",
    "        filename = None\n",
    "\n",
    "        if dataset_name in ['VH', 'WMH2017']:\n",
    "            # Reconstruct filename: e.g., VH_648_5.png\n",
    "            filename = f\"{dataset_name}_{subject_id}_{slice_id}.png\"\n",
    "\n",
    "        elif dataset_name == 'SHIFTS':\n",
    "            # Subject IDs are strings like 'train14' or 'eval_in2512'\n",
    "            if subject_id.startswith('train_'):\n",
    "                subject_num = subject_id.replace('train_', '')\n",
    "                filename = f\"train_{subject_num}_{slice_id}.png\"\n",
    "            elif subject_id.startswith('dev_in_'):\n",
    "                nums = subject_id.replace('dev_in_', '')\n",
    "                filename = f\"dev_in_{nums}_{slice_id}.png\"\n",
    "            elif subject_id.startswith('eval_in_'):\n",
    "                nums = subject_id.replace('eval_in_', '')\n",
    "                filename = f\"eval_in_{nums}_{slice_id}.png\"\n",
    "            elif subject_id.startswith('dev_out_'):\n",
    "                nums = subject_id.replace('dev_out_', '')\n",
    "                filename = f\"dev_out_{nums}_{slice_id}.png\"\n",
    "\n",
    "        if filename is None:\n",
    "            print(f\"Warning: could not reconstruct filename for subject {subject_id}, slice {slice_id}\")\n",
    "            continue\n",
    "\n",
    "        src_path = os.path.join(src_dir, filename)\n",
    "        dst_path = os.path.join(dst_dir, filename)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "        else:\n",
    "            print(f\"File not found: {src_path}\")\n",
    "\n",
    "def segment_flair_folder(dst_dir_flair):\n",
    "    # Output folders in ./test_images\n",
    "    base_dir = os.path.dirname(dst_dir_flair.rstrip(\"/\"))\n",
    "    bkgnd_dir = os.path.join(base_dir, \"BKGND\")\n",
    "    csf_dir = os.path.join(base_dir, \"CSF\")\n",
    "    # wm_dir = os.path.join(base_dir, \"WM\")\n",
    "    # gm_dir = os.path.join(base_dir, \"GM\")\n",
    "    wm_gm_dir = os.path.join(base_dir, \"WM_GM\")\n",
    "    os.makedirs(bkgnd_dir, exist_ok=True)\n",
    "    os.makedirs(csf_dir, exist_ok=True)\n",
    "    # os.makedirs(wm_dir, exist_ok=True)\n",
    "    # os.makedirs(gm_dir, exist_ok=True)\n",
    "    os.makedirs(wm_gm_dir, exist_ok=True)\n",
    "\n",
    "    png_files = [f for f in os.listdir(dst_dir_flair) if f.endswith(\".png\") and os.path.isfile(os.path.join(dst_dir_flair, f))]\n",
    "\n",
    "    for filename in png_files:\n",
    "        path = os.path.join(dst_dir_flair, filename)\n",
    "        arr = np.array(Image.open(path).convert(\"L\")).astype(np.float32)\n",
    "\n",
    "        # Create ANTs image\n",
    "        img = ants.from_numpy(arr)\n",
    "        mask = ants.get_mask(img)\n",
    "\n",
    "        # Run Atropos\n",
    "        seg = ants.atropos(\n",
    "            a=img,\n",
    "            m='[0.2,1x1]',\n",
    "            c='[2,0]',\n",
    "            i='kmeans[3]',\n",
    "            x=mask,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Get segmentation labels\n",
    "        seg_image = seg[\"segmentation\"]\n",
    "        unique_labels = np.unique(seg_image.numpy())\n",
    "        means = [img.numpy()[seg_image.numpy() == l].mean() for l in unique_labels]\n",
    "        sorted_labels = np.argsort(means)\n",
    "\n",
    "        # Assign labels based on sorted means\n",
    "        bkgnd_label = unique_labels[sorted_labels[0]]\n",
    "        csf_label = unique_labels[sorted_labels[1]]\n",
    "        wm_label  = unique_labels[sorted_labels[2]]\n",
    "        gm_label  = unique_labels[sorted_labels[3]]\n",
    "\n",
    "        # Create masks\n",
    "        bkgnd_mask = (seg_image == bkgnd_label).numpy().astype(np.uint8) * 255\n",
    "        csf_mask = (seg_image == csf_label).numpy().astype(np.uint8) * 255\n",
    "        # wm_mask = (seg_image == wm_label).numpy().astype(np.uint8) * 255\n",
    "        # gm_mask = (seg_image == gm_label).numpy().astype(np.uint8) * 255\n",
    "        wm_gm_mask = (seg_image == wm_label).numpy().astype(np.uint8) * 255 + (seg_image == gm_label).numpy().astype(np.uint8) * 255\n",
    "\n",
    "        # Save masks\n",
    "        Image.fromarray(bkgnd_mask).save(os.path.join(bkgnd_dir, filename))\n",
    "        Image.fromarray(csf_mask).save(os.path.join(csf_dir, filename))\n",
    "        # Image.fromarray(wm_mask).save(os.path.join(wm_dir, filename))\n",
    "        # Image.fromarray(gm_mask).save(os.path.join(gm_dir, filename))\n",
    "        Image.fromarray(wm_gm_mask).save(os.path.join(wm_gm_dir, filename))\n",
    "\n",
    "        print(f\"Segmented and saved: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40654f2",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93219bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/benet/data/lesion2D_VH-SHIFTS-WMH2017_empty_masks/test/mask\"\n",
    "\n",
    "df_vh = build_area_table(directory, 'VH')\n",
    "df_wmh = build_area_table(directory, 'WMH2017')\n",
    "df_shifts = build_area_table(directory, 'SHIFTS')\n",
    "\n",
    "# # Save to CSV or display\n",
    "# df_vh.to_csv(\"vh_mask_area_table.csv\")\n",
    "# print(df_vh.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721612dd",
   "metadata": {},
   "source": [
    "#### 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "031e3ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum total area: 67\n",
      "Selected subjects per slice:\n",
      "Slice 0: Subject 648\n",
      "Slice 1: Subject 741\n",
      "Slice 2: Subject 729\n",
      "Slice 3: Subject 739\n",
      "Slice 4: Subject 745\n",
      "Slice 5: Subject 746\n",
      "Slice 6: Subject 749\n",
      "Slice 7: Subject 738\n",
      "Slice 8: Subject 727\n",
      "Slice 9: Subject 751\n",
      "Slice 10: Subject 752\n",
      "Slice 11: Subject 754\n",
      "Slice 12: Subject 758\n"
     ]
    }
   ],
   "source": [
    "total_area_vh, best_combo_vh = solve_min_area_ilp(df_vh)\n",
    "\n",
    "print(\"Minimum total area:\", total_area_vh)\n",
    "print(\"Selected subjects per slice:\")\n",
    "for sl in sorted(best_combo_vh):\n",
    "    print(f\"Slice {sl}: Subject {best_combo_vh[sl]}\")\n",
    "\n",
    "src_dir_mask = \"/home/benet/data/lesion2D_VH-SHIFTS-WMH2017_empty_masks/test/mask\"\n",
    "src_dir_flair = \"/home/benet/data/lesion2D_VH-SHIFTS-WMH2017_empty_masks/test/flair\"\n",
    "dst_dir_mask = \"./test_images/mask\"\n",
    "dst_dir_flair = \"./test_images/flair\"\n",
    "copy_selected_masks(df_vh, best_combo_vh, 'VH', src_dir_mask, dst_dir_mask)\n",
    "copy_selected_masks(df_vh, best_combo_vh, 'VH', src_dir_flair, dst_dir_flair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fda4099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum total area: 3803\n",
      "Selected subjects per slice:\n",
      "Slice 0: Subject 56\n",
      "Slice 1: Subject 50\n",
      "Slice 2: Subject 132\n",
      "Slice 3: Subject 65\n",
      "Slice 4: Subject 101\n",
      "Slice 5: Subject 59\n",
      "Slice 6: Subject 103\n",
      "Slice 7: Subject 58\n",
      "Slice 8: Subject 137\n",
      "Slice 9: Subject 27\n",
      "Slice 10: Subject 33\n",
      "Slice 11: Subject 6\n",
      "Slice 12: Subject 126\n"
     ]
    }
   ],
   "source": [
    "total_area_wmh, best_combo_wmh = solve_min_area_ilp(df_wmh)\n",
    "\n",
    "print(\"Minimum total area:\", total_area_wmh)\n",
    "print(\"Selected subjects per slice:\")\n",
    "for sl in sorted(best_combo_wmh):\n",
    "    print(f\"Slice {sl}: Subject {best_combo_wmh[sl]}\")\n",
    "\n",
    "src_dir_mask = \"/home/benet/data/lesion2D_VH-SHIFTS-WMH2017_empty_masks/test/mask\"\n",
    "src_dir_flair = \"/home/benet/data/lesion2D_VH-SHIFTS-WMH2017_empty_masks/test/flair\"\n",
    "dst_dir_mask = \"./test_images/mask\"\n",
    "dst_dir_flair = \"./test_images/flair\"\n",
    "copy_selected_masks(df_wmh, best_combo_wmh, 'WMH2017', src_dir_mask, dst_dir_mask)\n",
    "copy_selected_masks(df_wmh, best_combo_wmh, 'WMH2017', src_dir_flair, dst_dir_flair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae07562a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum total area: 299\n",
      "Selected subjects per slice:\n",
      "Slice 0: Subject train_22\n",
      "Slice 1: Subject dev_in_4\n",
      "Slice 2: Subject train_6\n",
      "Slice 3: Subject eval_in_18\n",
      "Slice 4: Subject dev_out_24\n",
      "Slice 5: Subject train_14\n",
      "Slice 6: Subject train_32\n",
      "Slice 7: Subject dev_out_22\n",
      "Slice 8: Subject dev_out_25\n",
      "Slice 9: Subject eval_in_4\n",
      "Slice 10: Subject eval_in_25\n",
      "Slice 11: Subject train_4\n",
      "Slice 12: Subject eval_in_30\n"
     ]
    }
   ],
   "source": [
    "total_area_shifts, best_combo_shifts = solve_min_area_ilp(df_shifts)\n",
    "\n",
    "print(\"Minimum total area:\", total_area_shifts)\n",
    "print(\"Selected subjects per slice:\")\n",
    "for sl in sorted(best_combo_shifts):\n",
    "    print(f\"Slice {sl}: Subject {best_combo_shifts[sl]}\")\n",
    "\n",
    "src_dir_mask = \"/home/benet/data/lesion2D_VH-SHIFTS-WMH2017_empty_masks/test/mask\"\n",
    "src_dir_flair = \"/home/benet/data/lesion2D_VH-SHIFTS-WMH2017_empty_masks/test/flair\"\n",
    "dst_dir_mask = \"./test_images/mask\"\n",
    "dst_dir_flair = \"./test_images/flair\"\n",
    "copy_selected_masks(df_shifts, best_combo_shifts, 'SHIFTS', src_dir_mask, dst_dir_mask)\n",
    "copy_selected_masks(df_shifts, best_combo_shifts, 'SHIFTS', src_dir_flair, dst_dir_flair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963d33e",
   "metadata": {},
   "source": [
    "#### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b18e01f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented and saved: WMH2017_27_9.png\n",
      "Segmented and saved: eval_in_30_12.png\n",
      "Segmented and saved: dev_out_22_7.png\n",
      "Segmented and saved: dev_out_24_4.png\n",
      "Segmented and saved: VH_749_6.png\n",
      "Segmented and saved: VH_741_1.png\n",
      "Segmented and saved: train_14_5.png\n",
      "Segmented and saved: eval_in_18_3.png\n",
      "Segmented and saved: VH_746_5.png\n",
      "Segmented and saved: VH_752_10.png\n",
      "Segmented and saved: VH_727_8.png\n",
      "Segmented and saved: VH_754_11.png\n",
      "Segmented and saved: WMH2017_132_2.png\n",
      "Segmented and saved: WMH2017_58_7.png\n",
      "Segmented and saved: WMH2017_103_6.png\n",
      "Segmented and saved: dev_out_25_8.png\n",
      "Segmented and saved: eval_in_4_9.png\n",
      "Segmented and saved: train_22_0.png\n",
      "Segmented and saved: VH_758_12.png\n",
      "Segmented and saved: train_4_11.png\n",
      "Segmented and saved: WMH2017_56_0.png\n",
      "Segmented and saved: train_32_6.png\n",
      "Segmented and saved: WMH2017_50_1.png\n",
      "Segmented and saved: train_6_2.png\n",
      "Segmented and saved: dev_in_4_1.png\n",
      "Segmented and saved: WMH2017_59_5.png\n",
      "Segmented and saved: WMH2017_6_11.png\n",
      "Segmented and saved: WMH2017_101_4.png\n",
      "Segmented and saved: WMH2017_137_8.png\n",
      "Segmented and saved: WMH2017_65_3.png\n",
      "Segmented and saved: WMH2017_33_10.png\n",
      "Segmented and saved: VH_751_9.png\n",
      "Segmented and saved: WMH2017_126_12.png\n",
      "Segmented and saved: VH_729_2.png\n",
      "Segmented and saved: VH_745_4.png\n",
      "Segmented and saved: VH_738_7.png\n",
      "Segmented and saved: eval_in_25_10.png\n",
      "Segmented and saved: VH_648_0.png\n",
      "Segmented and saved: VH_739_3.png\n"
     ]
    }
   ],
   "source": [
    "segment_flair_folder(\"./test_images/flair\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf420045",
   "metadata": {},
   "source": [
    "#### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "59fdaeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.ndimage import label\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_lesions(mask):\n",
    "    \"\"\"Extract binary lesion components from a mask.\"\"\"\n",
    "    labeled, n = label(mask)\n",
    "    lesions = []\n",
    "    for i in range(1, n + 1):\n",
    "        lesion = (labeled == i).astype(np.uint8) * 255\n",
    "        if lesion.sum() > 0:\n",
    "            lesions.append(lesion)\n",
    "    return lesions\n",
    "\n",
    "def transform_lesion(lesion, target_shape):\n",
    "    \"\"\"Randomly transform a lesion (rotate, scale).\"\"\"\n",
    "    h, w = lesion.shape\n",
    "    scale = random.uniform(0.8, 1.2)\n",
    "    angle = random.uniform(-20, 20)\n",
    "    lesion_resized = cv2.resize(lesion, None, fx=scale, fy=scale)\n",
    "    M = cv2.getRotationMatrix2D((lesion_resized.shape[1] // 2, lesion_resized.shape[0] // 2), angle, 1)\n",
    "    lesion_rotated = cv2.warpAffine(lesion_resized, M, (lesion_resized.shape[1], lesion_resized.shape[0]))\n",
    "\n",
    "    # Ensure lesion fits target\n",
    "    lh, lw = lesion_rotated.shape\n",
    "    if lh >= target_shape[0] or lw >= target_shape[1]:\n",
    "        return None\n",
    "    return lesion_rotated\n",
    "\n",
    "def paste_lesions(target_shape, lesion_list, max_lesions=5):\n",
    "    \"\"\"Paste transformed lesions into a blank mask.\"\"\"\n",
    "    new_mask = np.zeros(target_shape, dtype=np.uint8)\n",
    "    attempts = 0\n",
    "    while attempts < max_lesions:\n",
    "        lesion = random.choice(lesion_list)\n",
    "        lesion_transformed = transform_lesion(lesion, target_shape)\n",
    "        if lesion_transformed is None:\n",
    "            continue\n",
    "        lh, lw = lesion_transformed.shape\n",
    "        x_offset = random.randint(0, target_shape[0] - lh)\n",
    "        y_offset = random.randint(0, target_shape[1] - lw)\n",
    "        region = new_mask[x_offset:x_offset+lh, y_offset:y_offset+lw]\n",
    "        new_mask[x_offset:x_offset+lh, y_offset:y_offset+lw] = np.maximum(region, lesion_transformed)\n",
    "        attempts += 1\n",
    "    return new_mask\n",
    "\n",
    "def generate_synthetic_mask(source_mask_dir, slice_id, dataset, output_path):\n",
    "    \"\"\"Generate a synthetic lesion mask for a given slice using lesions from other brains.\"\"\"\n",
    "    lesion_bank = []\n",
    "    for fname in os.listdir(source_mask_dir):\n",
    "        if not fname.endswith(\".png\"):\n",
    "            continue\n",
    "        if dataset in fname and f\"_{slice_id}.png\" in fname:\n",
    "            mask = np.array(Image.open(os.path.join(source_mask_dir, fname)).convert(\"L\"))\n",
    "            lesions = extract_lesions(mask)\n",
    "            lesion_bank.extend(lesions)\n",
    "\n",
    "    if len(lesion_bank) == 0:\n",
    "        print(f\"No lesion masks found for slice {slice_id} in {dataset}\")\n",
    "        return\n",
    "\n",
    "    # Create new synthetic mask\n",
    "    target_shape = lesion_bank[0].shape\n",
    "    synthetic_mask = paste_lesions(target_shape, lesion_bank)\n",
    "\n",
    "    # Save or visualize\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    Image.fromarray(synthetic_mask).save(output_path)\n",
    "\n",
    "    # Also return for quick viewing here\n",
    "    return synthetic_mask\n",
    "\n",
    "# Example usage\n",
    "source_mask_dir = \"/home/benet/data/lesion2D_VH-SHIFTS-WMH2017_empty_masks/test/mask\"\n",
    "example_output = generate_synthetic_mask(source_mask_dir, slice_id=1, dataset=\"WMH2017\",\n",
    "                                         output_path=\"./synthetic_masks/VH_slice5.png\")\n",
    "\n",
    "if example_output is not None:\n",
    "    plt.imshow(example_output, cmap='gray')\n",
    "    plt.title(\"Synthetic Mask Example\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "16062d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.ndimage import label\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def extract_lesions(mask):\n",
    "    \"\"\"Extract binary lesion components from a mask.\"\"\"\n",
    "    labeled, n = label(mask)\n",
    "    lesions = []\n",
    "    for i in range(1, n + 1):\n",
    "        lesion = (labeled == i).astype(np.uint8) * 255\n",
    "        area = np.sum(lesion > 0)\n",
    "        lesions.append((lesion, area))\n",
    "    return lesions\n",
    "\n",
    "\n",
    "def categorize_lesions(lesions):\n",
    "    \"\"\"Divide lesions into small, medium, and large based on area.\"\"\"\n",
    "    areas = [a for _, a in lesions]\n",
    "    if len(areas) < 3:\n",
    "        return {'small': [], 'medium': [], 'large': []}\n",
    "\n",
    "    # Use percentiles to divide\n",
    "    small_th = np.percentile(areas, 33)\n",
    "    large_th = np.percentile(areas, 66)\n",
    "\n",
    "    categorized = {'small': [], 'medium': [], 'large': []}\n",
    "    for lesion, area in lesions:\n",
    "        if area <= small_th:\n",
    "            categorized['small'].append(lesion)\n",
    "        elif area <= large_th:\n",
    "            categorized['medium'].append(lesion)\n",
    "        else:\n",
    "            categorized['large'].append(lesion)\n",
    "\n",
    "    # print how many lesions in each category\n",
    "    print(f\"Small lesions: {len(categorized['small'])}\")\n",
    "    print(f\"Medium lesions: {len(categorized['medium'])}\")\n",
    "    print(f\"Large lesions: {len(categorized['large'])}\")\n",
    "    return categorized\n",
    "\n",
    "\n",
    "def transform_lesion(lesion, target_shape, seed=None):\n",
    "    \"\"\"Randomly transform a lesion (rotate, scale).\"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    scale = random.uniform(0.9, 1.1)\n",
    "    angle = random.uniform(-15, 15)\n",
    "    lesion_resized = cv2.resize(lesion, None, fx=scale, fy=scale, interpolation=cv2.INTER_NEAREST)\n",
    "    M = cv2.getRotationMatrix2D((lesion_resized.shape[1] // 2, lesion_resized.shape[0] // 2), angle, 1)\n",
    "    lesion_rotated = cv2.warpAffine(lesion_resized, M, (lesion_resized.shape[1], lesion_resized.shape[0]), flags=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Ensure lesion fits target\n",
    "    lh, lw = lesion_rotated.shape\n",
    "    if lh >= target_shape[0] or lw >= target_shape[1]:\n",
    "        return None\n",
    "    return lesion_rotated\n",
    "\n",
    "\n",
    "def paste_lesions(target_shape, lesion_dict, wm_mask, seed=None):\n",
    "    \"\"\"Paste one small, one medium, and one large lesion into a blank mask within WM/GM.\"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    new_mask = np.zeros(target_shape, dtype=np.uint8)\n",
    "    categories = ['small', 'medium', 'large']\n",
    "\n",
    "    for cat in categories:\n",
    "        if not lesion_dict[cat]:\n",
    "            continue\n",
    "\n",
    "        tries = 0\n",
    "        while tries < 20:\n",
    "            lesion = random.choice(lesion_dict[cat])\n",
    "            lesion_transformed = transform_lesion(lesion, target_shape, seed)\n",
    "            if lesion_transformed is None:\n",
    "                tries += 1\n",
    "                continue\n",
    "\n",
    "            lh, lw = lesion_transformed.shape\n",
    "            x_offset = random.randint(0, target_shape[0] - lh)\n",
    "            y_offset = random.randint(0, target_shape[1] - lw)\n",
    "\n",
    "            # Check if target region in WM/GM mask\n",
    "            region = wm_mask[x_offset:x_offset+lh, y_offset:y_offset+lw]\n",
    "            if np.sum(region > 0) / (lh * lw) < 0.8:  # at least 80% must be WM/GM\n",
    "                tries += 1\n",
    "                continue\n",
    "\n",
    "            new_mask[x_offset:x_offset+lh, y_offset:y_offset+lw] = np.maximum(\n",
    "                new_mask[x_offset:x_offset+lh, y_offset:y_offset+lw], lesion_transformed)\n",
    "            break\n",
    "\n",
    "    return new_mask\n",
    "\n",
    "\n",
    "def generate_synthetic_mask(source_mask_dir, slice_id, dataset, wm_mask_path, output_path, seed=42):\n",
    "    \"\"\"Generate a synthetic lesion mask for a given slice using other subjects' lesions.\"\"\"\n",
    "    lesion_bank = []\n",
    "    for fname in os.listdir(source_mask_dir):\n",
    "        if not fname.endswith(\".png\"):\n",
    "            continue\n",
    "        if dataset in fname and f\"_{slice_id}.png\" in fname:\n",
    "            mask = np.array(Image.open(os.path.join(source_mask_dir, fname)).convert(\"L\"))\n",
    "            lesions = extract_lesions(mask)\n",
    "            lesion_bank.extend(lesions)\n",
    "\n",
    "    if len(lesion_bank) < 3:\n",
    "        print(f\"Not enough lesions for slice {slice_id} in {dataset}\")\n",
    "        return\n",
    "\n",
    "    lesion_dict = categorize_lesions(lesion_bank)\n",
    "    if not all(lesion_dict[cat] for cat in ['small', 'medium', 'large']):\n",
    "        print(f\"Missing categories for slice {slice_id} in {dataset}\")\n",
    "        return\n",
    "\n",
    "    # Load WM/GM mask\n",
    "    wm_mask = np.array(Image.open(wm_mask_path).convert(\"L\"))\n",
    "    target_shape = wm_mask.shape\n",
    "\n",
    "    synthetic_mask = paste_lesions(target_shape, lesion_dict, wm_mask, seed=seed)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    Image.fromarray(synthetic_mask).save(output_path)\n",
    "\n",
    "    return synthetic_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "11dd391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small lesions: 24\n",
      "Medium lesions: 23\n",
      "Large lesions: 24\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_mask_dir = \"/home/benet/data/lesion2D_VH-SHIFTS-WMH2017_empty_masks/test/mask\"\n",
    "wm_mask_path = \"./test_images/WM_GM/VH_746_5.png\"  # Example WM/GM mask\n",
    "output_path = \"./synthetic_masks/VH_slice5.png\"\n",
    "\n",
    "example_output= generate_synthetic_mask(\n",
    "    source_mask_dir=source_mask_dir,\n",
    "    slice_id=5,\n",
    "    dataset=\"VH\",\n",
    "    wm_mask_path=wm_mask_path,\n",
    "    output_path=output_path,\n",
    "    # seed=17844  # reproducibility\n",
    ")\n",
    "\n",
    "if example_output is not None:\n",
    "    plt.imshow(example_output, cmap='gray')\n",
    "    plt.title(\"Synthetic Mask Example\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benetvicorob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
