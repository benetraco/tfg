{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 16:38:56.684543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747060736.706170 1464378 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747060736.712694 1464378 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747060736.729142 1464378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747060736.729161 1464378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747060736.729164 1464378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747060736.729166 1464378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-12 16:38:56.735496: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from build_dataset import MRILesionDatasetBuilder, LatentImageProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the dataset for the brain generation model\n",
    "- Inpaint lesions with simple method in the slices with lesions\n",
    "- Include SHIFTS and WMH2017 datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total empty masks skipped: 0\n",
      "In the preprocessed folder: Total examples: 741, train examples: 507 (68.42%), test examples: 234 (31.58%)\n",
      "In the hole dataset: Total examples: 741, train examples: 507 (68.42%), test examples: 234 (31.58%)\n"
     ]
    }
   ],
   "source": [
    "data_folder=\"/home/benet/data\"\n",
    "input_folder=\"VH\"\n",
    "output_folder=\"generation2D_VH-SHIFTS-WMH2017\"\n",
    "folders=[\"train\", \"test\"]\n",
    "flair_image=\"flair.nii.gz\"\n",
    "mask_image=\"lesionMask.nii.gz\"\n",
    "slices_per_example=13\n",
    "slices_step=1\n",
    "start_slice=85\n",
    "train_split=1\n",
    "seed = 17844\n",
    "skip_empty_masks=False\n",
    "fill_lesion=True\n",
    "\n",
    "# dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "# dataset_builder.build_dataset()\n",
    "\n",
    "\n",
    "# output_folder=\"lesion2D_VH\"\n",
    "# fill_lesion=False\n",
    "# dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "# dataset_builder.build_dataset()\n",
    "\n",
    "output_folder=\"lesion2D_VH_split\"\n",
    "fill_lesion=False\n",
    "train_split=0.7\n",
    "dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "dataset_builder.build_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/benet/tfg\n",
      "Device: cuda\n",
      "Found 507 images in the dataset folder\n",
      "2028 latent images saved in /home/benet/data/lesion2D_VH_split/train/latent\n",
      "Device: cuda\n",
      "Found 234 images in the dataset folder\n",
      "936 latent images saved in /home/benet/data/lesion2D_VH_split/test/latent\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "repo_path= Path.cwd().resolve()\n",
    "while '.gitignore' not in os.listdir(repo_path): # while not in the root of the repo\n",
    "    repo_path = repo_path.parent #go up one level\n",
    "    print(repo_path)\n",
    "resolution = 256\n",
    "processor_train = LatentImageProcessor(repo_path, output_dir = \"/home/benet/data/lesion2D_VH_split/train/latent\", scale=True, \n",
    "                                 resolution=resolution, finetuned_vae=False, input_dir = \"/home/benet/data/lesion2D_VH_split/train/flair\")\n",
    "processor_train.process_images()\n",
    "\n",
    "processor_test = LatentImageProcessor(repo_path, output_dir = \"/home/benet/data/lesion2D_VH_split/test/latent\", scale=True,\n",
    "                                    resolution=resolution, finetuned_vae=False, input_dir = \"/home/benet/data/lesion2D_VH_split/test/flair\")\n",
    "processor_test.process_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHIFTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total empty masks skipped: 0\n",
      "In the preprocessed folder: Total examples: 1274, train examples: 1274 (100.00%), test examples: 0 (0.00%)\n",
      "In the hole dataset: Total examples: 2015, train examples: 2015 (100.00%), test examples: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "data_folder=\"/home/benet/data\"\n",
    "input_folder=\"SHIFTS_preprocessedMNI\" ###\n",
    "output_folder=\"generation2D_VH-SHIFTS-WMH2017\"\n",
    "folders=[\"dev_in\", \"dev_out\", \"eval_in\", \"train\"] ###\n",
    "flair_image=\"flair.nii.gz\"\n",
    "mask_image=\"lesionMask.nii.gz\"\n",
    "slices_per_example=13\n",
    "slices_step=1\n",
    "start_slice=85\n",
    "train_split=1\n",
    "seed = 17844\n",
    "skip_empty_masks=False\n",
    "fill_lesion=True\n",
    "\n",
    "dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "dataset_builder.build_dataset()\n",
    "\n",
    "\n",
    "# output_folder=\"lesion2D_SHIFTS\"\n",
    "# fill_lesion=False\n",
    "# dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "# dataset_builder.build_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMH2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total empty masks skipped: 0\n",
      "In the preprocessed folder: Total examples: 780, train examples: 780 (100.00%), test examples: 0 (0.00%)\n",
      "In the hole dataset: Total examples: 2795, train examples: 2795 (100.00%), test examples: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "data_folder=\"/home/benet/data\"\n",
    "input_folder=\"WMH2017_preprocessedMNI\" ###\n",
    "output_folder=\"generation2D_VH-SHIFTS-WMH2017\"\n",
    "folders=None ###\n",
    "flair_image=\"flair.nii.gz\"\n",
    "mask_image=\"lesionMask.nii.gz\"\n",
    "slices_per_example=13\n",
    "slices_step=1\n",
    "start_slice=85\n",
    "train_split=1\n",
    "seed = 17844\n",
    "skip_empty_masks=False\n",
    "fill_lesion=True\n",
    "\n",
    "dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "dataset_builder.build_dataset()\n",
    "\n",
    "\n",
    "# output_folder=\"lesion2D_WMH2017\"\n",
    "# fill_lesion=False\n",
    "# dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "# dataset_builder.build_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benetvicorob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
