{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from build_dataset import MRILesionDatasetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MRILesionDatasetBuilder:\n",
    "    def __init__(self, data_folder=\"/home/benet/data\", input_folder=\"VH\", output_folder=\"lesion2D\", folders=[\"train\", \"test\"], flair_image=\"flair.nii.gz\",\n",
    "                 mask_image=\"lesionMask.nii.gz\", slices_per_example=13, slices_step=1, start_slice=85, train_split=0.7, seed=17844, skip_empty_masks=True,\n",
    "                 fill_lesion=False):\n",
    "        self.data_folder = data_folder\n",
    "        self.input_folder = input_folder\n",
    "        self.output_folder = os.path.join(data_folder, output_folder)\n",
    "        self.folders = folders\n",
    "        self.flair_image = flair_image\n",
    "        self.mask_image = mask_image\n",
    "        self.slices_per_example = slices_per_example\n",
    "        self.slices_step = slices_step\n",
    "        self.start_slice = start_slice\n",
    "        self.train_split = train_split\n",
    "        self.seed = seed\n",
    "        np.random.seed(seed)\n",
    "        self.skip_empty_masks = skip_empty_masks\n",
    "        self.fill_lesion = fill_lesion\n",
    "        self._create_output_dirs()\n",
    "    \n",
    "    def _create_output_dirs(self):\n",
    "        \"\"\"Creates necessary output directories.\"\"\"\n",
    "        sub_dirs = [\"train/flair\", \"train/mask\", \"test/flair\", \"test/mask\"]\n",
    "        for sub_dir in sub_dirs:\n",
    "            os.makedirs(os.path.join(self.output_folder, sub_dir), exist_ok=True)\n",
    "    \n",
    "    def build_dataset(self):\n",
    "        \"\"\"Processes all specified folders (train/test).\"\"\"\n",
    "        empty_masks, train_count, test_count = 0, 0, 0\n",
    "        if self.input_folder == \"VH\":\n",
    "            train_examples, test_examples = 0, 0\n",
    "            total_examples = sum(len(os.listdir(os.path.join(self.data_folder, self.input_folder, folder))) for folder in self.folders)\n",
    "            for folder in self.folders:\n",
    "                folder_path = os.path.join(self.data_folder, self.input_folder, folder)\n",
    "                examples = sorted(os.listdir(folder_path))\n",
    "                \n",
    "                for example in examples:\n",
    "                    if train_examples >= total_examples * self.train_split:\n",
    "                        train_test = \"test\"\n",
    "                        example_empty_masks = self._process_example(folder_path, example, folder, train_test)\n",
    "                    elif test_examples >= total_examples * (1 - self.train_split):\n",
    "                        train_test = \"train\"\n",
    "                        example_empty_masks = self._process_example(folder_path, example, folder, train_test)\n",
    "                    else:\n",
    "                        train_test = folder\n",
    "                        example_empty_masks = self._process_example(folder_path, example, folder, train_test)\n",
    "                    \n",
    "                    empty_masks += example_empty_masks\n",
    "                    increment = self.slices_per_example - example_empty_masks\n",
    "                    train_count += (train_test == \"train\") * increment\n",
    "                    test_count += (train_test == \"test\") * increment\n",
    "                    train_examples += (train_test == \"train\")\n",
    "                    test_examples += (train_test == \"test\")\n",
    "\n",
    "        elif self.input_folder == \"SHIFTS_preprocessedMNI\":\n",
    "            for folder in self.folders:\n",
    "                folder_path = os.path.join(self.data_folder, self.input_folder, folder)\n",
    "                examples = os.listdir(folder_path)\n",
    "                np.random.shuffle(examples)\n",
    "                examples_train = examples[:int(len(examples) * self.train_split)]\n",
    "                examples_test = examples[int(len(examples) * self.train_split):]\n",
    "                for example in examples_train:\n",
    "                    example_empty_masks = self._process_example(folder_path, example, folder, \"train\")\n",
    "                    empty_masks += example_empty_masks\n",
    "                    train_count += self.slices_per_example - example_empty_masks\n",
    "                for example in examples_test:\n",
    "                    example_empty_masks = self._process_example(folder_path, example, folder, \"test\")\n",
    "                    empty_masks += example_empty_masks\n",
    "                    test_count += self.slices_per_example - example_empty_masks\n",
    "\n",
    "        elif self.input_folder == \"WMH2017_preprocessedMNI\":\n",
    "            folder_path = os.path.join(self.data_folder, self.input_folder)\n",
    "            examples = os.listdir(folder_path)\n",
    "            np.random.shuffle(examples)\n",
    "            examples_train = examples[:int(len(examples) * self.train_split)]\n",
    "            examples_test = examples[int(len(examples) * self.train_split):]\n",
    "            for example in examples_train:\n",
    "                example_empty_masks = self._process_example(folder_path, example, None, \"train\")\n",
    "                empty_masks += example_empty_masks\n",
    "                train_count += self.slices_per_example - example_empty_masks\n",
    "            for example in examples_test:\n",
    "                example_empty_masks = self._process_example(folder_path, example, None, \"test\")\n",
    "                empty_masks += example_empty_masks\n",
    "                test_count += self.slices_per_example - example_empty_masks\n",
    "        \n",
    "        else:\n",
    "            print(f\"Unknown input folder: {self.input_folder}, only 'VH' and 'SHIFTS_preprocessedMNI' and 'WMH2017_preprocessedMNI' are supported.\")\n",
    "            return\n",
    "                \n",
    "        print(f\"Total empty masks skipped: {empty_masks}\")\n",
    "\n",
    "        print(f\"In the preprocessed folder: Total examples: {train_count + test_count}, train examples: {train_count} ({train_count/(train_count + test_count) * 100:.2f}%), test examples: {test_count} ({test_count/(train_count + test_count) * 100:.2f}%)\")\n",
    "\n",
    "        train_count_total = len(os.listdir(os.path.join(self.output_folder, \"train/flair\")))\n",
    "        test_count_total = len(os.listdir(os.path.join(self.output_folder, \"test/flair\")))\n",
    "        print(f\"In the hole dataset: Total examples: {train_count_total + test_count_total}, train examples: {train_count_total} ({train_count_total/(train_count_total + test_count_total) * 100:.2f}%), test examples: {test_count_total} ({test_count_total/(train_count_total + test_count_total) * 100:.2f}%)\")\n",
    "\n",
    "    def _process_example(self, folder_path, example, folder, train_test=None):\n",
    "        \"\"\"Processes a single example folder.\"\"\"\n",
    "        example_path = os.path.join(folder_path, example)\n",
    "        if not os.path.isdir(example_path):\n",
    "            print(f\"Skipping {example_path}\")\n",
    "            return\n",
    "        \n",
    "        flair_path = os.path.join(example_path, self.flair_image)\n",
    "        mask_path = os.path.join(example_path, self.mask_image)\n",
    "        flair_data, mask_data = self._load_nifti_images(flair_path, mask_path)\n",
    "        \n",
    "        return self._save_slices(example, flair_data, mask_data, folder, train_test)   \n",
    "      \n",
    "    def _load_nifti_images(self, flair_path, mask_path):\n",
    "        \"\"\"Loads NIfTI images and returns their data arrays.\"\"\"\n",
    "        flair = nib.load(flair_path).get_fdata()\n",
    "        mask = nib.load(mask_path).get_fdata()\n",
    "        assert flair.shape == mask.shape, \"Flair and Mask shapes do not match!\"\n",
    "        return flair, mask\n",
    "    \n",
    "    def _save_slices(self, example, flair_data, mask_data, folder, train_test=None):\n",
    "        \"\"\"Extracts and saves slices as PNG files.\"\"\"\n",
    "        end_slice = self.start_slice + self.slices_per_example * self.slices_step\n",
    "        empty_masks = 0\n",
    "        for j, i in enumerate(range(self.start_slice, end_slice, self.slices_step)):\n",
    "            flair_slice = np.rot90(flair_data[:, :, i])\n",
    "            mask_slice = np.rot90(mask_data[:, :, i])\n",
    "            \n",
    "            # If mask_slice is empty, skip saving\n",
    "            if self.skip_empty_masks and np.sum(mask_slice) == 0:\n",
    "                print(f\"Skipping empty mask for {folder} {example} at slice {i}\")\n",
    "                empty_masks += 1\n",
    "                continue\n",
    "        \n",
    "            # If fill_lesion is True, fill the lesion in the flair image with a gray value (0-255)\n",
    "            if self.fill_lesion:\n",
    "                # mid = (np.max(flair_slice) - np.min(flair_slice)) / 2\n",
    "                # mean of flair_slice excuding where pixels are 0\n",
    "                # zero_pixels = np.where(flair_slice == 0)\n",
    "                # print(f\"Number of zero pixels in flair slice: {len(zero_pixels[0])}\")\n",
    "                mean = np.mean(flair_slice[flair_slice > 0])\n",
    "                flair_slice[mask_slice > 0] = mean\n",
    "                # print(f\"Filling lesion for {folder} {example} at slice {i}\")\n",
    "                # print the maximum value in the flair slice and the minimum\n",
    "                # print(f\"Max value in flair slice: {np.max(flair_slice)}, Min value in flair slice: {np.min(flair_slice)}\")\n",
    "\n",
    "            self._save_image(flair_slice, \"flair\", example, j, folder, train_test)\n",
    "            self._save_image(mask_slice, \"mask\", example, j, folder, train_test)\n",
    "\n",
    "        return empty_masks\n",
    "    \n",
    "    def _save_image(self, slice_data, image_type, example, index, folder, train_test=None):\n",
    "        \"\"\"Saves a single image slice as PNG.\"\"\"\n",
    "        if self.input_folder == \"VH\": # VH dataset folder is already train/test\n",
    "            path = os.path.join(self.output_folder, train_test, image_type, f\"{self.input_folder}_{example}_{index}.png\")\n",
    "        elif self.input_folder == \"SHIFTS_preprocessedMNI\":\n",
    "            path = os.path.join(self.output_folder, train_test, image_type, f\"{folder}_{example}_{index}.png\")\n",
    "        elif self.input_folder == \"WMH2017_preprocessedMNI\":\n",
    "            path = os.path.join(self.output_folder, train_test, image_type, f\"WMH2017_{example}_{index}.png\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown input folder: {self.input_folder}\")\n",
    "               \n",
    "        plt.imsave(path, slice_data, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the dataset for the brain generation model\n",
    "- Inpaint lesions with simple method in the slices with lesions\n",
    "- Include SHIFTS and WMH2017 datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total empty masks skipped: 0\n",
      "In the preprocessed folder: Total examples: 741, train examples: 507 (68.42%), test examples: 234 (31.58%)\n",
      "In the hole dataset: Total examples: 741, train examples: 507 (68.42%), test examples: 234 (31.58%)\n"
     ]
    }
   ],
   "source": [
    "data_folder=\"/home/benet/data\"\n",
    "input_folder=\"VH\"\n",
    "output_folder=\"generation2D_VH-SHIFTS-WMH2017\"\n",
    "folders=[\"train\", \"test\"]\n",
    "flair_image=\"flair.nii.gz\"\n",
    "mask_image=\"lesionMask.nii.gz\"\n",
    "slices_per_example=13\n",
    "slices_step=1\n",
    "start_slice=85\n",
    "train_split=1\n",
    "seed = 17844\n",
    "skip_empty_masks=False\n",
    "fill_lesion=True\n",
    "\n",
    "# dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "# dataset_builder.build_dataset()\n",
    "\n",
    "\n",
    "# output_folder=\"lesion2D_VH\"\n",
    "# fill_lesion=False\n",
    "# dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "# dataset_builder.build_dataset()\n",
    "\n",
    "output_folder=\"lesion2D_VH_split\"\n",
    "fill_lesion=False\n",
    "train_split=0.7\n",
    "dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "dataset_builder.build_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHIFTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total empty masks skipped: 0\n",
      "In the preprocessed folder: Total examples: 1274, train examples: 1274 (100.00%), test examples: 0 (0.00%)\n",
      "In the hole dataset: Total examples: 2015, train examples: 2015 (100.00%), test examples: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "data_folder=\"/home/benet/data\"\n",
    "input_folder=\"SHIFTS_preprocessedMNI\" ###\n",
    "output_folder=\"generation2D_VH-SHIFTS-WMH2017\"\n",
    "folders=[\"dev_in\", \"dev_out\", \"eval_in\", \"train\"] ###\n",
    "flair_image=\"flair.nii.gz\"\n",
    "mask_image=\"lesionMask.nii.gz\"\n",
    "slices_per_example=13\n",
    "slices_step=1\n",
    "start_slice=85\n",
    "train_split=1\n",
    "seed = 17844\n",
    "skip_empty_masks=False\n",
    "fill_lesion=True\n",
    "\n",
    "dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "dataset_builder.build_dataset()\n",
    "\n",
    "\n",
    "# output_folder=\"lesion2D_SHIFTS\"\n",
    "# fill_lesion=False\n",
    "# dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "# dataset_builder.build_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMH2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total empty masks skipped: 0\n",
      "In the preprocessed folder: Total examples: 780, train examples: 780 (100.00%), test examples: 0 (0.00%)\n",
      "In the hole dataset: Total examples: 2795, train examples: 2795 (100.00%), test examples: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "data_folder=\"/home/benet/data\"\n",
    "input_folder=\"WMH2017_preprocessedMNI\" ###\n",
    "output_folder=\"generation2D_VH-SHIFTS-WMH2017\"\n",
    "folders=None ###\n",
    "flair_image=\"flair.nii.gz\"\n",
    "mask_image=\"lesionMask.nii.gz\"\n",
    "slices_per_example=13\n",
    "slices_step=1\n",
    "start_slice=85\n",
    "train_split=1\n",
    "seed = 17844\n",
    "skip_empty_masks=False\n",
    "fill_lesion=True\n",
    "\n",
    "dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "dataset_builder.build_dataset()\n",
    "\n",
    "\n",
    "# output_folder=\"lesion2D_WMH2017\"\n",
    "# fill_lesion=False\n",
    "# dataset_builder = MRILesionDatasetBuilder(data_folder, input_folder, output_folder, folders, flair_image, mask_image, slices_per_example, slices_step, start_slice, train_split, seed, skip_empty_masks, fill_lesion)\n",
    "# dataset_builder.build_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benetvicorob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
